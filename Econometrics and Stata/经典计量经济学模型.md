---
Date: 19th February 2024
Doctype: Note
Category: 02_Writing Books/Econometrics and Stata/经典计量经济学模型.md
Status: Draft
Abstract: 
Keywords: 
tags: 
Version: 1.0.0
License: MIT
Copyright: © 2024 FAN WANG. All rights reserved.
---
---
# 回归分析是什么
## 为什么回归分析是计量经济学的核心：
- 回归、相关、因果
	- 回归关系：自变量与因变量间，如何影响，可能推知因果，回归方程
	- 相关关系：两个变量间，是否影响，无法推知因果，相关系数
	- 因果关系：两个变量（概念）间，影响，（难以预知）定性
	注意：回归分析通常从分析相关关系开始。因此在建立回归模型之前，通常首先计算相关系数来了解变量之间的线性关系强度和方向。 同时有
	$$\beta = \frac{\rho \times \sigma_y}{\sigma_x}$$ ( β 代表回归系数, ρ 代表相关系数, σ<sub>y</sub> ​代表因变量的标准差, σ<sub>x</sub>​ 代表自变量的标准差)
	
- 计量经济学的本质是对经济关系的因果分析，因此回归分析是最重要的方法之一
# 单方程单变量回归
### 基本模型：总体回归函数（PRF）与样本回归函数（SRF）
$$
\begin{aligned}
\text{PRF:}\quad E(Y|X_i) &= \beta_0 + \beta_1 X_i \\
\text{SRF:}\quad \hat{Y}_i &= \hat{\beta_0} + \hat{\beta_1} X_i 
\end{aligned}
$$
```tikz
\usetikzlibrary{decorations.pathreplacing}

\begin{document}
\begin{tikzpicture}

\draw[thick, ->] (-0.2,0) --(6,0) node[right] {$X$};
\draw[thick, ->] (0,-0.2) --(0,7) node[above] {$Y$};

\draw[domain = 1:5, dashed] plot (\x,{1*\x}) node[right]{$SRF:\hat{Y}_i = \hat{\beta}_1 + \hat{\beta}_2X_i
$};
\draw[domain = 1:5] plot (\x,{0.5*\x+1}) node[right]{$PRF:E(Y|X_i) = \beta_1 + \beta_2X_i$};
\draw[domain = 0:6, dashed, color = black!25] plot ({4},\x) node[below] at(4,0) {$X_i$};
\draw[domain = 0:4, dashed, color = black!25] plot (\x,{4}) node[left] at(0,4) {$\hat{Y_i}$};
\draw[domain = 0:4, dashed, color = black!25] plot (\x,{3}) node[left] at(0,3) {$E(Y|X_i)$};
\draw[domain = 0:4, dashed, color = black!25] plot (\x,{6}) node[left] at(0,6) {$Y_i$};

\draw[|<->|] (4,4) -- (4,6) node[fill=white,midway] {$\hat{u_i}$};

\draw [decorate, decoration={brace, amplitude=5pt, raise=1pt, mirror}] (4,3) -- (4,6) node [black,midway,xshift=38pt] {$u_i = E(u|X_i)$};

\end{tikzpicture}
\end{document}
```
基本的单变量单方程回归
PRF：条件期望函数（CES）-总体回归函数（PRF）
- 对参数线性
```tikz
\usepackage{pgfplots}
\pgfplotsset{compat=newest}
\begin{document}
\begin{tikzpicture}
\begin{axis}[
    xlabel={X-axis label},
    ylabel={Y-axis label},
    xmin=0, xmax=250,
    ymin=50, ymax=300,
    xtick={0,50,...,250},
    ytick={0,50,...,300},
    legend pos=north east,
    ymajorgrids=true,
    grid style=dashed,
]

% Here you would insert your data points
\addplot[only marks, color=red, mark=*]
table {
    10  240
    50  215
    100 190
    150 165
    200 120
    230 80
};
\addlegendentry{Sample Points}


\addplot[only marks, color=yellow, mark=*]
table {
	10 243 
	50 215 
	100 180 
	150 145 
	200 110 
	230 89
};
\addlegendentry{$E(Y|X_i)$}

\addplot[only marks, color=blue, mark=*]
table {
    10  238
    10  235
    10  265
    50  210
    50  223
    50  206
    100 185
    100 193
    100 178
    150 163
    150 172
    150 164
    200 130
    200 107
    200 117
    230 95
    230 70
    230 60
};
\addlegendentry{Population}

% Here you would insert the equation of your trend line
\addplot[
    color=red,
    domain=0:250,
]
{-(0.7)*x + 250}; % Replace the equation with the one that fits your data
\addlegendentry{PRF}

\end{axis}
\end{tikzpicture}

\end{document}
```
注意：
1. $E(Y|X_i)$是在PRF线上的，PRF线是由总体点形成的，样本的红点形成的是SRF线，，且不位于SRF线上，它与SRF线上对应的$Y_i$点的距离为$u_i$，对其的计量因为OLS和MLE的方法形成了不同的流派
2. 由上文可知随着样本点数量的上升，SRF逼近PRF，预测的$\hat{Y_i}$逼近$E(Y|X_i)$
3. 必须意识到一个事实，$E(Y|X_i)$之于PRF和$\hat{Y_i}$之于SRF的重要性是一样的，那么，对于$\hat{Y_i}$会随着样本点数量的变化和估计方式的不同，相应的$E(Y|X_i)$也应该受到总体点数量变化的影响和某种估计方式的决定，前者是总体样本数是不可测的且在计量中固定，后者则是由定义决定。
4. $E(Y|X_i)$为条件期望，因为是在分组的条件下 ，此时条件概率会变化，即从总体无条件概率变为条件概率，前者用于无条件期望的加权
5. 
6. 样本数量上升之后，分组后可以存在样本的条件期望 $E(Y_i|X_i)$,虽然在基本估计模型中SRF参数是由$u_i$和估计方法的不同来界定的，即SRF不是通过连线的方式形成，那么这个$E(Y_i|X_i)$是否有价值？不考虑，无价值，两个样本合一考虑

	1. 样本均值的期望等于总体期望：因为样本均值服服从计算期望的分布（如果对一般SRF而言是均匀分布），由中心极限定理，收敛于总体的均值即总体期望（此时因为SRF抽样是均匀分布，所以此时期望等同与均值，因为加权一样，SRF合为PRF，为总体即总体期望——等权时算术平均数等于加权平均数）[[统计推断-无偏性]]
	2. 样本方差的期望等于总体方差


### 核心：对$u_i$的估计 
$$Y_i= E(Y|X_i) + u_i = \hat{Y_i}+\hat{u_i}$$
注：$\hat{Y_i}是E(Y|X_i)的估计量，不是Y_i的！$
#### OLS法-残差平方和
$$min\sum \hat{u_i}^2=\sum (Y_i-\hat{Y_i})^2$$
结果为:
$$
\begin{aligned}
\hat{\beta_2} &= \frac{\sum x_iy_i}{\sum x_i^2} \\ &= \frac{\sum x_iY_i}{\sum X_i^2 - n\bar{X}^2} \\ &= \frac{\sum X_iy_i}{\sum X_i^2 - n\bar{X}^2}
\\ \hat{\beta_1} &= \frac{\sum X_i^2\sum Y_i^2-\sum X_i\sum X_iY_i}{n\sum X_i^2-(\sum X_i)^2}
\end{aligned}
$$
注意：$\hat{\beta_1}$有几种运算：
1. 将求解$\hat{\beta_2}$时使用拉格朗日乘数法得的方程组消去$\hat{\beta_2}$保留$\hat{\beta_1}$即可
2. 使用$\bar{X}$与$\bar{Y}$：由题必然有$$\begin{aligned} \sum Y_i&=n\hat{\beta_1}+\hat{\beta_2} \sum X_i \\ &\downarrow 除\space n\\ \bar{Y}&=\hat{\beta_1}+\hat{\beta_2} \bar{X}\end{aligned}$$
变异$=\sigma^2*\mathcal{df}$
	度量：拟合优度（$0<r^2<1$）$$
	\begin{aligned} 
	\sum y_i^2 &= \beta_2^2\sum x_i^2 + \sum \hat{u_i}^2 
	\\
	\\ TSS&=ESS+RSS
	\\
	\\ r^2 &= \frac{ESS}{TSS}=\frac{[\sum(Y_i-\bar{Y})(\hat{Y_i}-\bar{Y})]^2}{\sum(Y_i-\bar{Y})^2\sum(\hat{Y_i}-\bar{Y})^2} 
	\end{aligned} 
	$$
##### 核心：
###### 已知的定义或式子
$$
\begin{aligned} 
\sum \hat{u_i}&=\sum \hat{u_i}X_i=0 (拉格朗日乘数法设为0:附注) 
\\
Y_i&=\hat{Y_i}+\hat{u_i}
\\
\bar{Y}&=\hat{\beta_1}+\hat{\beta_2} \bar{X}
\\
\end{aligned}
$$
###### 推导出的定义
$$
\begin{aligned}
\hat{u}&=0 
\\ 
\bar{\hat{Y}}&=\bar{Y} 
\\
y_i&=\hat{\beta_2}x_i+\hat{u_i} \space 注意u_i等于0的进一步解释
\\
\sum&\hat{u_i}X_i=\sum\hat{u_i}Y_i=0 \space 不相关
\end{aligned}
$$
证明见[[证明]]











###### 尺度单位、模型选用与标准化回归
- 尺度因子的影响不一定是全局的
- 标准化变量以避免尺度问题--备注！！！！！
- $$
\begin{aligned} 
\hat{\beta}_2^* &= (\frac{w_1}{w_2}) \hat{\beta_2}
\\
\hat{\beta}_1^* &= w_1 \hat{\beta_1}
\\
\hat{\sigma}^{*2} &= w_1^2 \hat{\sigma}^2
\\
var(\hat{\beta}^*_1) &= w_1^2 var(\hat{\beta_1})
\\
var(\hat{\beta}^*_2) &= (\frac{w_1}{w_2})^2 var(\hat{\beta_2})
\\
r_{x^*y^*}^2 &= r_{xy}^2
\end{aligned} 
$$

|分类|   模型   | 函数 | 导数 | 弹性 | 例子 |
|:---:|:--------:|:----:|:----:|:----:|:----:|
||   线性   | $Y=\beta_1 + \beta_2X$     | $\beta_2$     | $\beta_2(\frac{Y}{X})$     |      |
|半对数模型 |   对数   | $Y=\beta_1 + \beta_2lnX$     | $\beta_2(\frac{1}{X})$      | $\beta_2(\frac{1}{Y})$      | 恩格尔曲线     |
|倒数模型 |   倒数   | $Y=\beta_1 + \beta_2(\frac{1}{X})$     | $-\beta_2(\frac{1}{X^2})$     | $-\beta_2(\frac{1}{XY})$      | 菲利普斯线     |
|半对数模型 | 对数线性 | $lnY=\beta_1 + \beta_2X$     | $\beta_2Y$     | $\beta_2X$     | 复利与增长     |
|对数线性模型| 对数对数 | $lnY=\beta_1 + \beta_2lnX$     | $\beta_2(\frac{Y}{X})$     | $\beta_2$     | 弹性分析     |
|倒数模型 | 对数倒数         | $lnY=\beta_1 - \beta_2(\frac{1}{X})$     | $\beta_2(\frac{Y}{X^2})$     | $\beta_2(\frac{1}{X})$      | 短期生产线     |









##### 无截距假定
1. 对参数线性
2. $Cov(X_i,u_i)=0$ — 与NLRM模型区别
3. $E(u_i|X_i)=0$ — 不存在设定偏误（2的另一种表述） 
4. $var(u_i)=c$ — 方差齐性
5. $cov(u_i,u_j|X_i,X_j)=E(u_iu_j)=0$ — 无自相关
6. $n > i$ — 观测大于估计
7. $X_i$无异常 — 波动值
8. $\color{red}\sum u_i = 0$<font color="#ff0000"> （不一定!）</font>
9. $\color{red}-1<r_2<1$<font color="#ff0000">（可能&lt;0!）</font>$\color{red} raw \space r_2 = \frac{(\sum X_iY_i)^2}{\sum X_i^2 \sum Y_i^2}$
##### 无截距假定下参数的数字特征
$$
\begin{aligned}
\hat{\beta_2} &= \frac{\sum X_iY_i}{\sum X_i^2} \sim \mathcal{F}(\beta_2,\frac{\sigma^2}{\sum X_i^2}) 
\\ \hat{\sigma}^2 &= \frac{\sum \hat{u_i}^2}{n-1} \sim \mathcal{F}(\sigma^2 ,?)
\\ E(Y|X_i) &= \beta_1 X_i \sim 
\\ \hat{Y_i} &= \hat{\beta_1} X_i \sim \mathcal{F}(\beta_1X_i,?)
\\ Y_i &= \hat{Y_i} + \hat{u_i}= \hat{\beta_1} X_i + \hat{u_i} \sim 
\end{aligned}
$$

##### CLRM假定
1. 对参数线性
2. $Cov(X_i,u_i)=0$ — 与NLRM模型区别
3. $E(u_i|X_i)=0$ — 不存在设定偏误（2的另一种表述） 
4. $var(u_i)=c$ — 方差齐性
5. $cov(u_i,u_j|X_i,X_j)=E(u_iu_j)=0$ — 无自相关
6. $n > i$ — 观测大于估计
7. $X_i$无异常 — 波动值

###### CLRM假定下参数的数字特征 
$$
\begin{aligned}
\hat{\beta_2} &= \frac{\sum x_iy_i}{\sum x_i^2} \sim \mathcal{F}(\beta_2,\frac{\sigma^2}{\sum x_i^2}) 
\\ \hat{\beta_1} &= \frac{\sum X_i^2\sum Y_i^2-\sum X_i\sum X_iY_i}{n\sum X_i^2-(\sum X_i)^2} \sim \mathcal{F}(\beta_1,\frac{\sum X_i^2}{n\sum x_i^2}\sigma^2) 
\\ cov(\hat{\beta_1},\hat{\beta_2}) &= -\bar{X}var(\hat{\beta_2})
\\ \hat{\sigma}^2 &= \frac{\sum \hat{u_i}^2}{n-2} \sim \mathcal{F}(\sigma^2 ,?)
\\ E(Y|X_i) &= \beta_0 + \beta_1 X_i \sim 
\\ \hat{Y_i} &= \hat{\beta_0} + \hat{\beta_1} X_i \sim \mathcal{F}(\beta_2+\beta_1X_i,c[\frac{1}{n}+\frac{(X_i-\bar{X})^2}{\sum x_i^2}])
\\ Y_i &= \hat{Y_i} + \hat{u_i}= \hat{\beta_0} + \hat{\beta_1} X_i + \hat{u_i} \sim 
\end{aligned}
$$
推导见[[证明]]
$$
$$



##### CNLRM假定
1. 对参数线性
2. $Cov(X_i,u_i)=0$ — 与NLRM模型区别
3. $E(u_i|X_i)=0$ — 不存在设定偏误（2的另一种表述） 
4. $\color{red}var(u_i)=c$ <font color="#ff0000">— 方差齐性 --> </font>$\color{red}var(u_i)=\sigma^2$ <font color="#ff0000">— 方差齐性且服从标准正态</font>
5. $cov(u_i,u_j|X_i,X_j)=E(u_iu_j)=0$ — 无自相关
6. $n > i$ — 观测大于估计
7. $X_i$无异常 — 波动值
###### 参数的数字特征
 $$
\begin{aligned}
\hat{\beta_2} &= \frac{\sum x_iy_i}{\sum x_i^2} \sim \mathcal{N}(\beta_2,\frac{\sigma^2}{\sum x_i^2}) 
\\ \hat{\beta_1} &= \frac{\sum X_i^2\sum Y_i^2-\sum X_i\sum X_iY_i}{n\sum X_i^2-(\sum X_i)^2} \sim \mathcal{N}(\beta_1,\frac{\sum X_i^2}{n\sum x_i^2}\sigma^2) 
\\ cov(\hat{\beta_1},\hat{\beta_2}) &= -\bar{X}var(\hat{\beta_2})
\\ \hat{\sigma}^2 &= \frac{\sum \hat{u_i}^2}{n-2} \sim \mathcal{F}(\sigma^2 ,?)
\\ E(Y|X_i) &= \beta_0 + \beta_1 X_i \sim \mathcal{N}(\beta_2+\beta_1X_i,\sigma^2) 
\\ \hat{Y_i} &= \hat{\beta_0} + \hat{\beta_1} X_i \sim 
\\ Y_i &= E(Y|X_i) + u_i = \beta_0 + \beta_1 X_i + u_i \sim 
\end{aligned}
$$
[[检验问题]]




高斯马尔可夫定理
艾特肯定理
克鲁斯卡尔定理（P420）


# 单方程多变量回归
## 参数估计问题
### CLRM模型
假定：
1. 对参数线性
2. $Cov(X_i,u_i)=0$ — 与NLRM模型区别
3. $E(u_i|X_i)=0$ — 不存在设定偏误（2的另一种表述） 
4. $var(u_i)=c$ — 方差齐性
5. $cov(u_i,u_j|X_i,X_j)=E(u_iu_j)=0$ — 无自相关
6. $n > i$ — 观测大于估计
7. $X_i$无异常 — 波动值
8. $\color{red} X_i$<font color="#ff0000">间无多重共线性</font>

#### 参数估计
$$
\begin{aligned}
s.t.\space Y_i &= \hat{\beta_1} + \sum_{k=2}^{n} \hat{\beta_{k}}X_{ki}+\hat{u_i}
\\
min \space \sum_{i=1}^{m} \hat{u_i}^2 &= \sum_{i=1}^{m}(Y_i-\hat{\beta_1}-\sum_{k=2}^{n} \hat{\beta_{k}}X_{ki})^2
\end{aligned} 
$$
求解方式同单变量方程-拉格朗日乘数法
结果：
###### $R^2$的问题
1. 与偏回归系数方差的关系$$
var(\hat{\beta_j})=\frac{\sigma^2}{\sum x_j^2}(\frac{1}{1-R_j^2} ) $$
2. 与回归元数量成正比
3. $\bar{R^2}$ 与$R^2$关系
	1. 关系：$$
	\bar{R^2}=1-(1-R^2)\frac{n-1}{n-k} 
		$$
	2. 样本容量和因变量$f(y)$都必须相同
	3. $R^2$在回归元内不可分配
	4. r方和调整后的r方使用规则

ChatGPT

"R方"（R-squared）和"调整后的R方"（Adjusted R-squared）是统计学中用于回归分析的两个重要指标。它们的使用规则如下：

1. **R方（R-squared）**:
    
    - R方衡量的是回归模型对数据变异性的解释程度。
    - 它的值介于0到1之间，值越接近1，表示模型解释的变异性越高。
    - R方高并不总意味着模型就好，因为过拟合（模型对训练数据过度拟合，而不能很好地泛化到新数据）也会导致R方高。
2. **调整后的R方（Adjusted R-squared）**:
    
    - 调整后的R方是对R方的调整，以反映模型中自变量的数量。
    - 当向模型中添加更多的自变量时，即使这些变量对模型的解释不大，R方也可能会增加。调整后的R方通过对自变量数量进行惩罚来解决这个问题。
    - 一般来说，如果添加的自变量真的有助于模型，那么调整后的R方会增加；如果添加的自变量对模型没有帮助，调整后的R方则会降低。

在实际应用中，应该优先考虑使用调整后的R方来评估模型的解释力，特别是在模型中有多个自变量的情况下。它提供了一个更为公平和更具信息性的模型性能衡量标准。

调整后的R方一定更好吗

调整后的R方（Adjusted R-squared）并不是在所有情况下都比普通R方（R-squared）更好，但它在某些方面提供了更为合理的模型性能评估。下面是调整后R方的优势和局限性：

1. **惩罚自变量的数量**：调整后的R方对模型中自变量的数量进行调整。这意味着仅当新添加的自变量真正提高了模型的预测能力时，调整后的R方才会增加。这有助于防止过拟合。
    
2. **更适合比较模型**：当比较具有不同数量自变量的模型时，调整后的R方是一个更可靠的指标，因为它考虑了自变量的数量对模型性能的影响。
    
局限性：
1. **不总是提供直观的解释力度量**：调整后的R方可能会变成负值（尤其是在模型表现很差时），这在解释上可能不如原始的R方直观。
    
2. **不适用于所有情况**：对于一些特定类型的统计模型（如时间序列分析），调整后的R方可能不是最佳的性能衡量指标。
    
3. **依赖模型类型**：调整后的R方对模型的类型敏感。例如，在非线性回归情况下，它可能不如线性回归中有效。

总的来说，调整后的R方在处理具有多个自变量的模型时更为可靠，特别是在进行模型比较时。然而，它并不是在所有情况下都是最佳选择，而且它的解释需要更多的谨慎。在使用时，最好结合其他统计指标和模型的具体情况来综合评估模型性能。

###### 多项式回归
对于非标准的，假设是多项式型，不同次方前的参数是否会反应其影响里的高低，例如，对于X_1的、beta_1是否是影响力最低的

在多项式回归模型中，不同次方项前的系数（例如 β1β1​, β2β2​ 等）代表了该变量在不同次方下对因变量 YY 的影响。然而，这些系数的大小并不直接反映其影响力的高低，原因如下：

1. **不同次方的比较**：多项式回归模型可能包括某个自变量的不同次方项，如 X1,X12,X13X1​,X12​,X13​ 等。这些不同次方的系数（如 β1β1​ 对应于 X1X1​，β2β2​ 对应于 X12X12​）不能直接比较，因为它们影响 YY 的方式不同。
    
2. **尺度问题**：系数的大小也受到相应自变量单位的影响。例如，如果 X1X1​ 表示以年为单位的时间，而 X12X12​ 则表示以年的平方计的时间，这两个变量的尺度不同，使得直接比较其系数变得没有意义。
    
3. **系数解释**：在多项式回归中，较低次方的系数（如 β1β1​）通常解释为 X1X1​ 的线性影响，而更高次方的系数（如 β2β2​）则解释为 X1X1​ 的非线性影响。这些系数表明了变量在不同层次上如何影响因变量。
    
4. **模型的整体考虑**：在多项式回归中，我们通常关注的是整个模型的拟合度和预测能力，而不是单独的系数。一个系数的影响必须在整个模型的上下文中考虑。
    
5. **统计显著性**：除了系数的大小外，其统计显著性（通常通过 p-值判断）也是评估其影响的重要因素。一个系数即使数值很大，如果不具备统计显著性，其影响也可能是有限的。
    

因此，理解多项式回归模型中每个系数的含义需要综合考虑模型结构、变量的尺度、统计显著性以及整体模型的拟合度。正确地解释这些系数对于理解模型非常重要。

从尺度问题和系数解释角度出发，那我有两个解释变量，希望用多项式回归，我改如何匹配变量该使用哪个次方的系数呢

在多项式回归中，当您有两个解释变量并想决定使用哪个次方的系数时，有几个关键因素需要考虑：

1. **问题的本质**：首先，考虑您的研究问题和解释变量与因变量之间的关系。某些关系可能天然就是非线性的，或者可能有理由相信变量间的关系在不同层次上发生变化。
    
2. **变量的尺度**：变量的单位和尺度对于决定使用哪个次方很重要。例如，如果一个变量在自然尺度上很小，那么高次项可能不会产生太大影响，反之亦然。
    
3. **交叉项和高次项**：
    
    - **交叉项（如 X1×X2X1​×X2​）**：考虑两个变量之间的相互作用。如果您认为一个变量的效果取决于另一个变量的水平，则应该包括交叉项。
    - **高次项（如 X12,X22,X13X12​,X22​,X13​ 等）**：如果您认为变量与因变量之间的关系是非线性的，那么包括高次项可能是有意义的。
4. **模型复杂度与过拟合风险**：在增加更多高次项和交叉项时，模型会变得更加复杂。过于复杂的模型可能会导致过拟合，即模型在训练数据上表现很好，但在新数据上表现不佳。
    
5. **统计和诊断分析**：利用统计检验（如 t-检验）来评估模型中各项的显著性。同时，使用诊断图表（如残差图）来评估模型是否恰当地捕获了数据中的关系。
    
6. **模型选择准则**：使用信息准则（如 AIC 或 BIC）来比较不同模型的拟合优度，同时考虑模型的复杂性。
    
总之，选择哪个次方的系数应基于您对问题的理解、数据的特性以及统计分析的结果。通常，建议从简单的模型开始，逐步增加复杂性，并通过统计检验和诊断分析来指导您的决策。在多项式回归中，平衡模型的复杂性和预测能力是关键。

## 假设检验问题
### CNLRM模型
假定：
1. 对参数线性
2. $Cov(X_i,u_i)=0$ — 与NLRM模型区别
3. $E(u_i|X_i)=0$ — 不存在设定偏误（2的另一种表述） 
4. $\color{red}var(u_i)=c$ <font color="#ff0000">— 方差齐性 --> </font>$\color{red}var(u_i)=\sigma^2$ <font color="#ff0000">— 方差齐性且服从标准正态</font>
5. $cov(u_i,u_j|X_i,X_j)=E(u_iu_j)=0$ — 无自相关
6. $n > i$ — 观测大于估计
7. $X_i$无异常 — 波动值
8. $\color{red} X_i$<font color="#ff0000">间无多重共线性</font>

#### 假设检验
##### 独立检验偏回归系数
同二元变量
##### 联合检验偏回归系数
- 全为零检验
	1. 独立检验的乘积$\neq$联合检验的结果
	2. 评估增量有效性与贡献
	3. F检验：$$\begin{aligned} F=\frac{MESS}{MRSS}=\frac{ESS/df_{组间}}{RSS/df_{组内}}=\frac{ESS/(k-1)}{RSS/(n-k)}=\frac{R^2/(k-1)}{(1-R^2)/(n-k)}\end{aligned}$$


- 系数相等检验
	1. 假设$$\begin{aligned} \hat{\beta_i}=\hat{\beta_j} &\equiv \hat{\beta_i} - \hat{\beta_j} =0\\t(n-k_{含截距的待估参数总个数})_\alpha &=\frac{(\hat{\beta_i}-\hat{\beta_j})-(\beta_i-\beta_j)}{se(\hat{\beta_i}-\hat{\beta_j})}\\&=\frac{\hat{\beta_i}-\hat{\beta_j}}{\sqrt{var(\hat{\beta_i})+var(\hat{\beta_j})-2cov(\hat{\beta_i},\hat{\beta_j})}}\end{aligned}$$
- 约束检验
	1. 补充
- 模型稳定性
	1. 邹至庄检验


# 虚拟变量问题

### 系数 ——> 级差截距系数
1. 虚拟变量陷阱 -- 截距项与完全共线性
2. 区分类别数和定性变量数 
	双变量异类别数的定性矩阵（1.3 2.2左为正常，右边为陷阱，含截距项）
	$$\begin{pmatrix}1&0&0&0 \\1&1&0&0 \\1&0&1&0 \\1&0&0&1 \\1&1&0&1 \\1&0&1&1\end{pmatrix} \quad \begin{pmatrix}1&1&0&0&1&0 \\1&0&1&0&1&0 \\1&0&0&1&1&0 \\1&1&0&0&0&1 \\1&0&1&0&0&1 \\1&0&0&1&0&1\end{pmatrix}$$
同秩但左边列无关

### 时间分析
### 分段分析
引入$f(x)D_i$，$D_i$控制转折

# 放松假设
模型设定和$u_i$问题
1. 对参数线性
2. $\color{red}Cov(X_i,u_i)=0$ 
3. $\color{red}E(u_i|X_i)=0$ <font color="#ff0000">— 不存在设定偏误（2的另一种表述） </font>
4. $var(u_i)=c$ 
5. $cov(u_i,u_j|X_i,X_j)=E(u_iu_j)=0$ — 无自相关
6. $X_i$间无多重共线性
7. $\color{red} u_i \sim \mathcal{N}$
数据的假定问题
8. $X_i$间无准确线性关系
9. 6. $n > i$ — 观测大于估计
10. $X_i$无异常 — 波动值


## 多重共线性
### 定义
- 等价无穷小～不确定
- 组合考虑—>组合的参数可估计出
#### 完全多重共线性
$var{\hat{\beta_i}} = \infty$
#### 不完全多重共线性

### 后果
1. 方差和协方差过大 $R_j^2$表示$X_j$对其余$k-2$个回归元进行回归（$k$个变量有$k-1$个回归元，除被选中外的回归元还有$k-2$个）$\begin{aligned}var(\hat{\beta_j} )=\frac{\sigma^2}{\sum x^2_j}(\frac{1}{1-R^2_j})=\frac{\sigma^2}{\sum x^2_j}VIF_j(方差膨胀因子)=\frac{\sigma^2}{\sum x^2_j}\frac{1}{TOL_j(容许度)}\end{aligned}$$
3. 置信曲区间过宽
4. 多系数的检验统计上不显著但$R^2$可能很高

### 检测
- 核心：样本特征，程度问题（非有无）
	1. $R^2$很高但多系数的t检验统计上不显著
	2. <font color="#ff0000">高的</font>$\color{red}\rho_{X_i,X_j}$<font color="#ff0000">（多充双充要）与</font>$\color{red}\rho_{u_i,u_j}$<font color="#ff0000">（控制其它变量，充要）</font>
	3. $VIF_j，TOL_j$以及经验法则（$VIF_j>10$）
	4. 克莱因的经验法则
	5. 本征值和病态指数（无<10，完全>30）$$CI(病态指数)=\sqrt{k(病态数)}=\sqrt{\frac{最大本征值}{最小本征值}}$$
	6. 辅助回归$$F_i(k-2,n-k+1) \sim \frac{{R^2_{X_i}}/(k-2)}{1-{R^2_{X_i}}/(n-k+1)}$$
#### 补救
1. 无为而治
2. 经验程序
	1. 先验程序排除
	2. 横截面与时间序列数据并用（P341）附注
	3. 剔除变量与偏误
	4. 添加数据
	5. 主元法
	6. 因子分析
	7. 脊回归
## 异方差性
### 定义
#### 方差变化的原因
1. 学习模型
2. 分配模型
3. 异常观测（数据采集）
4. 设定偏误
5. 某一回归元分布本身偏态
6. 不正确的数据变形和函数形式

$$\begin{aligned} 
var(u_i) =c &\xrightarrow[\text{高斯—马尔可夫定理}]{\text{OLS估计}} = \hat{\beta_i}\sim BLUE
\\
var(u_i) \neq c &\xrightarrow[\text{艾特肯定理（调整后）}]{\text{GLS估计}} = \hat{\beta_i}\sim BLUE
\end{aligned}$$

#### 存在自相关的OLS统计量
#### [[GLS估计]]
OLS一律过高估计了由GLS得到的正确的真实标准误，尤其$\alpha$较大时候

### 后果：对OLS统计量的影响
#### 考虑到异方差
#### 没考虑到异方差



### 检测
1. 图解法：$\hat{u_i}^2-\hat{Y_i}$和$\hat{u_i}^2-X_i$散点图
2. 帕克检验；显著则为异方差（先OLS求残差再作检验，这本质是个回归）
3. 格莱泽检验，对于大样本更适用，小样本不是很合适
4. 斯皮尔曼等级相关检验：对于每一解释变量（P380）
5. 戈德菲尔德-匡特检验（P381）
6. <font color="#ff0000">布罗施-帕甘-戈弗雷检验（P384）</font>
7. 怀特检验（P386）
8. 寇因克-巴塞特检验（P387）
### 补救
####  $\sigma_i^2$已知
GLS估计
####  $\sigma_i^2$未知
怀特的异方差校正标准误

## 序列相关性
### 定义
按时间（如在时间序列数据中）或空间（如横截面数据中）排序的观测序列各成员之间的相关
注：这一部分为教材中使用了t作为$AR(1)$的变量，这意味着是对时间序列进行分析，而对于时间序列中需要使用OLS的分析应该是时间序列平稳的，这意味着不存在自相关性，因此本部分强调的是在不稳定时间序列分析中使用OLS会出现的问题，对于横截面数据，把空间作为$AR(1)$的变量考虑更合适，但是本质上无异
#### 成因
1. 惯性
	1. 蛛网模型
	2. 滞后效应
2. 设定偏误
	1. 应含而未含
	2. 不正确的函数形式

$$\begin{aligned} 
cov(u_i,u_j|X_i,X_j)=E(u_iu_j)=0 &\xrightarrow[\text{高斯—马尔可夫定理}]{\text{OLS估计}} = \hat{\beta_i}\sim BLUE
\\
cov(u_i,u_j|X_i,X_j)=E(u_iu_j)\neq0 &\xrightarrow[\text{艾特肯定理（调整后）}]{\text{GLS估计}} = \hat{\beta_i}\sim BLUE
\end{aligned}$$
#### 存在自相关的OLS统计量
考虑$AR(1)$...详细见后

### 后果：对OLS统计量的影响
#### 考虑到自相关
$LUE --> 置信区间更宽$
#### 没考虑到自相关
[1](https://files.oaiusercontent.com/file-uiNS2ZPFa395A9CPFcDBiogC?se=2024-01-15T00%3A39%3A56Z&sp=r&sv=2021-08-06&sr=b&rscc=max-age%3D299%2C%20immutable&rscd=attachment%3B%20filename%3DWeChate451d5f8c976360914d82adad5d2f23a.jpg&sig=UB/He9VC/HFDCmnPfZnoLhnTQDFNEfFN3BxFcTJBsf4%3D)
1. 低估了真实的$\sigma^2$
2. 高估了$R^2$
3. t和F检验都不可靠

### 检测
1. 图解法
	1. 残差时间顺序图/标准化残差时间顺序图
	2. 邻期残差散点图/标准化邻期残差散点图 
2. 游程检验
3. 德宾-沃森d检验
4. <font color="#ff0000">布罗施-戈弗雷检验，</font>$\color{red} AR(1)$<font color="#ff0000">时是德宾-M检验</font>
### 补救
GLS方法





# 定性数据分析
又称定性回归响应模型，概率模型，可以理解为对因变量的虚拟变量，等号左边是个条件概率函数！故参数 $\neq$ 边际效应！在Probit模型中，这个条件概率函数是通过将解释变量 X的线性组合（乘以系数后的和）通过标准正态累积分布函数（CDF）转换为概率值来建模的。这个转换过程体现了 Y和 X之间的非线性关系，并且使得预测的概率始终位于0和1之间，适用于二元因变量的建模
i为y的计量，j为x的计量

## 一般非线性模型
### 定义
因变量为多分响应变量
#### LPM模型
又称线性概率模型$(Bernoulli)$
$$\begin{aligned} 
线性模型&:\space Y_i = E(Y|X_i) + u_i \\
线性概率模型&:\space Pr(Y_i=1\space or\space0|X_i)=P_{LPM}+u_i\\
&\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space=\sum_{j=0}^{k}\beta_jX_{ij}(X_{0i}=1)+u_i\\
注&:\space0\le E(Y_i|X_i)=P_{LPM}\le 1
\end{aligned}$$
问题：
1. $u_i\sim Bernoulli()$ 非正态小样本必须GLS，大样本由于中心极限定理可以OLS
2. $var(u_i)\neq \sigma^2$ 非正态小样本必须GLS，大样本由于中心极限定理可以OLS或怀特法
3. OLS不一定满足$0\le E(Y_i|X_i)=P_i \le1$的约束 ==> Logit模型 或者 Probit模型
4. $R^2$可信度不高
#### Logit模型

又称逻辑分布变换概率模型$(Logistic)$
$$
\begin{aligned} 
线性模型&:\space Y_i = E(Y|X_i) + u_i \\
Logit模型&:\space Pr(Y_i=1\space or\space0|X_i) = P_{Logit}+u_i \\
&\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space=\Lambda (P_{LPM})+u_i\\
&\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space=\frac{1}{1+e^{-P_{LPM}}}+u_i\\
&\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space=\frac{1}{1+e^{-\sum_{j=0}^{k}\beta_jX_{ij}(X_{0i}=1)}}+u_i\\
&\downarrow \space 计算作变换，对P_{LPM}做MLE \\
P_{LPM}&=ln(\frac{P_{Logit}}{1-P_{Logit}})\\
注:ln(\frac{P_{Logit}}{1-P_{Logit}})&理解为机会比率的对数值，结合翻译
\end{aligned}
$$
求出的是$P_{LPM}$!（Y轴上！）

##### 个体数据（二值）
ML法
##### 群组数据（处理后为0～1间的连续值）
$$\begin{aligned}
\because u_i\sim \mathcal{N}(0,\frac{1}{N_iP_i(1-P_i)})\end{aligned}$$ 所以采取GLS分析
注意：解释的语言，参数对应逆变换$[F^{-1}(\beta_j)-1]*100=(\frac{P_i}{1-P_i}_{X_i，百分比})$
#### Probit模型

又称正态分布变换概率模型$(Normal)$
$$
\begin{aligned}
线性模型&:\space Y_i = E(Y|X_i) + u_i \\
Probit模型&:\space Pr(Y_i=1\space or\space0|X_i) = P_{Probit}+u_i \\
&\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space=\Phi (P_{LPM})+u_i\\
&\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space= \frac{1}{\sqrt{2\pi}} \int_{-\infty}^{P_{LPM}} e^{-\frac{z^2}{2}} dz+u_i\\
&\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space= \frac{1}{\sqrt{2\pi}} \int_{-\infty}^{\sum_{j=0}^{k}\beta_jX_{ij}(X_{0i}=1)} e^{-\frac{z^2}{2}} dz+u_i\\
&\downarrow \space 计算作逆变换，对P_{Probit}做MLE \\
P_{LPM}&=\mathcal{F}^{-1}(P_{Probit})
\end{aligned}
$$
![[WeChat905c6c819efed4a57e5f7db95f5adfc1 1.jpg]]
注：0和1不是实际的概率，在变化后分散化在了界限$I_i=P_{Probit}$的两边，类似求积分，注意每个样本每个单位的$I_i=P_{Probit}$是不同的！求出的是$P_{LPM}$!（Y轴上！）
##### 个体数据（二值）
[[MLE法]]
##### 群组数据（处理后为0～1间的连续值）
注意：解释的语言，参数对应逆变换$\mathcal{F}^{-1}(P_{Probit})$
n.e.d解释...
### 检验 
#### 独立假设检验
##### t检验—基于MLE理论
#### 联合假设检验
##### Wald-LR检验（两者渐进等价）
服从$\mathcal{X^2}$分布
### 边际效应（ME）
这意味着此时参数大小代表增长速度！，正负代表上升下降！
$$ME=\frac{\partial Pr(Y_i=1\space or\space0|X_i)}{\partial x_{ij}}=\frac{\partial \mathcal{F}(P_{LPM})}{\partial x_{ij}}=\mathcal{f}(P_{LPM})\beta_j=\mathcal{f}(\sum_{j=0}^{k}\beta_jX_{ij}(X_{0i}=1))\beta_j $$
#### AME
$$AME=\frac{\sum_{i=1}^{n}ME}{n}$$
#### MEA
$$MEA=\frac{\partial Pr(Y_i=1\space or\space0|\bar{X_i})}{\partial {x_{ij}}}=\frac{\partial \mathcal{F}(\bar{P_{LPM})}}{\partial x_{ij}}=\mathcal{f}(\bar{P_{LPM}})\hat{\beta_j} =\mathcal{f}(\sum_{j=0}^{k}\hat{\beta}_j\bar{X_i})\hat{\beta_j}$$
#### MER
特定值
#### MED
$$MRDV=\mathcal{F} (\sum_{j=0}^{k}\beta_jX_{ij}(X_{0i}=1,X_{Di}=1)​)−\mathcal{F}(\sum_{j=0}^{k}\beta_jX_{ij}(X_{0i}=1,X_{Di}=0))$$

### 拟合评估
#### Pseudo-R<sup>2</sup>
$$\begin{aligned}
max_{MLE-\hat{\beta}}\space\space\space\space ln(L(\beta))&=\sum_{i=1}^{n}​[Pr(Y_i=1\space or\space0|X_i)*​ln(P_{LPM}​)+(1−Pr(Y_i=1\space or\space0|X_i)​)*ln(1−P_{LPM}​)]\\
Pseudo-R^2&=1-\frac{lnL(\hat{\beta})_{拟合模型}}{lnL(\hat{\beta}_0)_{空模型}}
\end{aligned}$$ 没有通常意义规定有多好，但是可以比较logit和probit优劣
#### Brier评分
$$Brier=\frac{\sum_{n}^{i=1}(Pr(Y_i=1\space or\space0|X_i)-\hat{P_{LPM}})}{n} $$
越接近0越好
#### [[检验问题]]-分类表





## 多项式非线性模型
### 定义
#### 多项logit模型
$$\begin{aligned} 
多项Logit模型&:\space Pr(Y_i=m|X_i) = P_{Logit}+u_i \\
&\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space=\Lambda_m(P_{LPM})+u_i\\
&\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space=\frac{e^{P_{LPM_h}}}{\sum_{h=0}^{m}e^{P_{LPM_h}}}+u_i\\
&\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space=\frac{e^{\sum_{j=0}^{k}\beta_{jh}X_{ij}(X_{0i}=1,\beta_{0j}=0)}}{\sum_{h=0}^{m}e^{\sum_{j=0}^{k}\beta_{jh}X_{ij}(X_{0i}=1,\beta_{0j}=0)}}+u_i\\
&\downarrow \space 计算作变换，对P_{LPM}做MLE \\
P_{LPM}&=ln(\frac{P_{Logit}}{1-P_{Logit}})\\
注:ln(\frac{P_{Logit}}{1-P_{Logit}})&理解为机会比率的对数值，结合翻译
\end{aligned}
$$
### 检验
同上
### 边际效应（ME）
同上
### 拟合评估


# 横截面分析
# 时间序列分析
## 动态自回归模型
考虑参数设置为 $\phi_{0,s_t}=\beta_0+\beta_tX_{t},\phi_{k,s_t}=\gamma_k$ 的$AR(n)$
## 分布滞后模型
$$\begin{aligned}
Y_t = \alpha + \sum_{i=0}^{k}\beta_iX_{t-i}+u_i\\
\therefore \beta_{X_{t-j}}=\sum_{i=0}^{j}\beta_i
\end{aligned}$$ 
![[WeChatb28632f9ec9650f2d04cab205f41a664.jpg]]

## Koyck模型
就是$AR(1)$下的动态自回归模型



# 面板分析









## 一阶差分算子
## 一阶比率算子
## n阶SAR模型（马尔可夫自回归模型）
$$
\begin{aligned} AR(n):\space &Y_t = \phi_{0,s_t}+\sum_{k=1}^{n}\phi_{k,s_t}Y_{t-k}+\epsilon_t \space \space \\注:&Y_t是测度为t时观测值
\\&\phi_{k,s_t}为自协方差系数 （滞后k期的自相关系数），即状态 s_t​ 下的模型参数
\\&s_t是一个随时间变化的马尔可夫链状态，改变由概率矩阵控制
\\&\epsilon_t为白噪音误差项（随机干扰项）\sim \mathcal{F} (0,\sigma^2 _\epsilon)\space and \space cov(\epsilon_t,\epsilon_{t+s})=0\\ &t\space若指时间为时间序列自相关（时间序列分析）\\ &t\space若指空间为空间序列自相关（横截面分析）\end{aligned}$$


## ARCH模型
$$ \begin{aligned} &Y_t = \mu + \epsilon_t \\ &\epsilon_t = \sigma_t z_t \\ &\sigma_t^2 = \alpha_0 + \sum_{i=1}^{p} \alpha_i \epsilon_{t-i}^2 \\ \text{注:}& Y_t \text{ 是测度为 } t \text{ 时的观测值} \\ & \mu \text{ 是均值项} \\ & \epsilon_t \text{ 是时刻 } t \text{ 的误差项} \\ & \sigma_t \text{ 是时刻 } t \text{ 的条件标准差} \\ & \alpha_0, \alpha_i \text{ 是模型参数} \\ & z_t \text{ 是独立同分布的随机变量，通常假设为标准正态分布} \\ & p \text{ 是模型的阶数} \end{aligned} $$

## GARCH模型
$$ \begin{aligned} &Y_t = \mu + \epsilon_t \\ &\epsilon_t = \sigma_t z_t \\ &\sigma_t^2 = \alpha_0 + \sum_{i=1}^{p} \alpha_i \epsilon_{t-i}^2 + \sum_{j=1}^{q} \beta_j \sigma_{t-j}^2 \\ \text{注:} & Y_t \text{ 是测度为 } t \text{ 时的观测值} \\ & \mu \text{ 是均值项} \\ & \epsilon_t \text{ 是时刻 } t \text{ 的误差项} \\ & \sigma_t \text{ 是时刻 } t \text{ 的条件标准差} \\ & \alpha_0, \alpha_i, \beta_j \text{ 是模型参数} \\ & z_t \text{ 是独立同分布的随机变量，通常假设为标准正态分布} \\ & p \text{ 是 ARCH 项的阶数} \\ & q \text{ 是 GARCH 项的阶数} \end{aligned} $$


## 二次项的问题